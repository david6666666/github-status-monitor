# Enhanced GitHub Stats Report - vllm-project Organization

Generated on: 2025-11-28 20:13:59 UTC

**ÁªüËÆ°ËåÉÂõ¥**: vllm-project ÁªÑÁªáÁöÑÊâÄÊúâ PR Ë¥°ÁåÆÔºàÂåÖÂê´‰ª£Á†ÅÂèòÊõ¥ÁªüËÆ°Ôºâ

![Enhanced GitHub Stats Chart](stats_chart.svg)

---

ËøôÊòØÊ†πÊçÆÂú® **vllm-project** ÁªÑÁªá‰∏≠ÁöÑ PR Ë¥°ÁåÆÔºàMerged PRs + Open PRsÔºâËøõË°åÁöÑÊéíÂ∫è„ÄÇ

ÊÄªÂÖ±ËøΩË∏™‰∫Ü 23 ‰∏™Áî®Êà∑Âú® vllm-project ÁªÑÁªá‰∏≠ÁöÑË¥°ÁåÆÊÉÖÂÜµ„ÄÇ

**ÊÄª‰ª£Á†ÅÂèòÊõ¥ÁªüËÆ°**: +12,136 Ë°åÊ∑ªÂä†, -1,243 Ë°åÂà†Èô§

### üë§ WeiQing Chen (@david6666666) - ÊÄªË¥°ÁåÆ: 18
**‰ª£Á†ÅÂèòÊõ¥**: +2,087 Ë°åÊ∑ªÂä†, -345 Ë°åÂà†Èô§

**Pull Requests (1 open, 17 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [[CI] Add Async Eplb nightly CI tests](https://github.com/vllm-project/vllm/pull/29385) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `open` | 2025-11-25 | - | 167 | 4 |
| [[Misc] remove useless v1 env](https://github.com/vllm-project/vllm/pull/29164) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-11-21 | 2025-11-21 09:41:20 UTC | 0 | 2 |
| [[Docs] GSM8K Accuracy Evaluation doc update](https://github.com/vllm-project/vllm/pull/25360) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-09-22 | 2025-09-22 02:49:13 UTC | 1 | 1 |
| [[Performance][MM] Building the inverse permutation in O(n) time in Qwen2_5_VisionTransformer](https://github.com/vllm-project/vllm/pull/24443) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-09-08 | 2025-09-09 07:24:11 UTC | 11 | 1 |
| [[Feature][P/D]: Optimize NIXL Connector xfer Launch](https://github.com/vllm-project/vllm/pull/23887) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-29 | 2025-09-03 19:14:30 UTC | 18 | 13 |
| [[Model] Support DP for ViT on Kimi-VL-A3B-Thinking-2506](https://github.com/vllm-project/vllm/pull/23817) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-28 | 2025-09-01 16:56:57 UTC | 157 | 62 |
| [[Seed] Add Seed-OSS Guide](https://github.com/vllm-project/recipes/pull/41) | [vllm-project/recipes](https://github.com/vllm-project/recipes) | `merged` | 2025-08-26 | 2025-08-28 08:14:21 UTC | 199 | 1 |
| [[Model] Support DP for ViT on MiniCPM-V-4](https://github.com/vllm-project/vllm/pull/23327) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-21 | 2025-08-23 02:14:42 UTC | 105 | 30 |
| [[Model] Support dp on ViT on GLM-4.5V](https://github.com/vllm-project/vllm/pull/23168) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-19 | 2025-09-02 10:48:19 UTC | 145 | 59 |
| [[Multimodal][Speculative Decoding]Eagle Eagle3 mm support, enablement on qwen2.5vl](https://github.com/vllm-project/vllm/pull/22872) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-14 | 2025-09-27 03:35:48 UTC | 210 | 45 |
| [[EPLB] Optimize EPLB for Async Rearrange Experts ](https://github.com/vllm-project/vllm/pull/22179) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-04 | 2025-11-24 14:08:29 UTC | 778 | 77 |
| [[Bugfix] EPLB load statistics problem](https://github.com/vllm-project/vllm/pull/22167) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-04 | 2025-08-07 04:07:54 UTC | 26 | 41 |
| [[Docs] Update features/disagg_prefill, add v1 examples and development](https://github.com/vllm-project/vllm/pull/22165) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-04 | 2025-08-07 07:59:23 UTC | 25 | 0 |
| [[Doc] Added warning of speculating with draft model](https://github.com/vllm-project/vllm/pull/22047) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-01 | 2025-08-01 09:11:56 UTC | 4 | 0 |
| [[Bugfix] Fix hermes tool parser handling of non-string argument types](https://github.com/vllm-project/vllm/pull/22002) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-07-31 | 2025-09-22 03:35:39 UTC | 166 | 7 |
| [[Docs] add offline serving multi-modal video input expamle Qwen2.5-VL](https://github.com/vllm-project/vllm/pull/21530) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-07-24 | 2025-07-26 01:37:32 UTC | 64 | 0 |
| [[Bugfix] Fix example disagg_example_p2p_nccl_xpyd.sh zombie process](https://github.com/vllm-project/vllm/pull/21437) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-07-23 | 2025-07-24 03:42:11 UTC | 1 | 0 |
| [[BugFix] Fix shared storage connector load kv only load attention layer](https://github.com/vllm-project/vllm/pull/21428) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-07-23 | 2025-07-26 14:07:41 UTC | 10 | 2 |
| **Total for WeiQing Chen** | | | | - | **2,087** | **345** |

### üë§ wuhang (@wuhang2014) - ÊÄªË¥°ÁåÆ: 12
**‰ª£Á†ÅÂèòÊõ¥**: +862 Ë°åÊ∑ªÂä†, -391 Ë°åÂà†Èô§

**Pull Requests (4 open, 8 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [[gpt-oss]Support lazy init mcp session](https://github.com/vllm-project/vllm/pull/24388) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `open` | 2025-09-07 | - | 99 | 62 |
| [[CI][gpt-oss] Enable python tool tests in CI](https://github.com/vllm-project/vllm/pull/24315) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-09-05 | 2025-10-06 04:20:07 UTC | 24 | 26 |
| [[Benchmarks]Accelerate random dataset generation](https://github.com/vllm-project/vllm/pull/24225) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `open` | 2025-09-04 | - | 86 | 11 |
| [[Doc][gpt-oss]Responses API supports streaming with built-in tools with MCP](https://github.com/vllm-project/recipes/pull/48) | [vllm-project/recipes](https://github.com/vllm-project/recipes) | `merged` | 2025-09-04 | 2025-09-04 05:18:20 UTC | 1 | 1 |
| [[Spec Decoding]Support Spec Decoding Metrics in DP Mode](https://github.com/vllm-project/vllm/pull/24049) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-09-01 | 2025-09-14 21:11:10 UTC | 54 | 38 |
| [[Doc][GPT-OSS]Background mode for built-in mcp tools](https://github.com/vllm-project/recipes/pull/45) | [vllm-project/recipes](https://github.com/vllm-project/recipes) | `merged` | 2025-08-30 | 2025-09-02 23:38:55 UTC | 1 | 1 |
| [[Feature][Responses API]Support MCP tools with streaming mode + background mode](https://github.com/vllm-project/vllm/pull/23927) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-29 | 2025-09-04 04:05:10 UTC | 138 | 26 |
| [[Feature][Responses API] Support MCP tool in background mode](https://github.com/vllm-project/vllm/pull/23494) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-24 | 2025-08-27 01:06:58 UTC | 164 | 136 |
| [[Bugfix]Enable zmq router handover to handle scaling-up after scaling-down in EEP](https://github.com/vllm-project/vllm/pull/23247) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `open` | 2025-08-20 | - | 3 | 0 |
| [[Bugfix]Fix EEP scale-up functionality](https://github.com/vllm-project/vllm/pull/22953) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `open` | 2025-08-15 | - | 133 | 7 |
| [[Bugfix] Add log prefix in non-dp mode engine core](https://github.com/vllm-project/vllm/pull/21889) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-07-30 | 2025-08-01 09:04:16 UTC | 75 | 81 |
| [[Bugfix]check health for engine core process exiting unexpectedly](https://github.com/vllm-project/vllm/pull/21728) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-07-28 | 2025-07-28 13:17:31 UTC | 84 | 2 |
| **Total for wuhang** | | | | - | **862** | **391** |

### üë§ Hongsheng Liu (@hsliuustc0106) - ÊÄªË¥°ÁåÆ: 7
**‰ª£Á†ÅÂèòÊõ¥**: +282 Ë°åÊ∑ªÂä†, -57 Ë°åÂà†Èô§

**Pull Requests (3 open, 4 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [vllm-omni post init and roadmap updates](https://github.com/vllm-project/vllm-project.github.io/pull/123) | [vllm-project/vllm-project.github.io](https://github.com/vllm-project/vllm-project.github.io) | `open` | 2025-11-28 | - | 109 | 0 |
| [[WIP][performance] DP for ViT in Intern S1 model](https://github.com/vllm-project/vllm/pull/24936) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `open` | 2025-09-16 | - | 86 | 22 |
| [[Multi-modality][performance] enable DP for ViT in Qwen-2.5-VL](https://github.com/vllm-project/vllm-ascend/pull/2709) | [vllm-project/vllm-ascend](https://github.com/vllm-project/vllm-ascend) | `open` | 2025-09-02 | - | 47 | 13 |
| [[Doc] Fix a syntax error of example code in structured_outputs.md](https://github.com/vllm-project/vllm/pull/22045) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-01 | 2025-08-01 07:01:22 UTC | 1 | 1 |
| [[Docs] Fix the example code of streaming chat completions in reasoning](https://github.com/vllm-project/vllm/pull/21825) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-07-29 | 2025-07-30 12:11:58 UTC | 12 | 14 |
| [[Doc] Added unmentioned required option "method" in the usage of EAGLE-3 based models](https://github.com/vllm-project/vllm/pull/21737) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-07-28 | 2025-08-12 07:14:51 UTC | 4 | 0 |
| [[Bugfix] [issue-21565] Fix the incompatibility issue with stream and named function calling when Thinking is disabled](https://github.com/vllm-project/vllm/pull/21573) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-07-25 | 2025-07-28 05:43:50 UTC | 23 | 7 |
| **Total for Hongsheng Liu** | | | | - | **282** | **57** |

### üë§ Chenguang Zheng (@fake0fan) - ÊÄªË¥°ÁåÆ: 5
**‰ª£Á†ÅÂèòÊõ¥**: +5,648 Ë°åÊ∑ªÂä†, -233 Ë°åÂà†Èô§

**Pull Requests (0 open, 5 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [[CI/Build] Fix crash due to removed VLLM_USE_V1 attribute in EPD](https://github.com/vllm-project/vllm/pull/28521) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-11-12 | 2025-11-12 07:09:33 UTC | 3 | 7 |
| [[bugfix] Missing cached item in beam search](https://github.com/vllm-project/vllm/pull/27874) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-10-31 | 2025-10-31 17:34:28 UTC | 10 | 18 |
| [[Core] Encoder separation for Encode-Prefill-Decode Disaggregation](https://github.com/vllm-project/vllm/pull/25233) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-09-19 | 2025-11-12 02:58:34 UTC | 5,025 | 41 |
| [[Core][Multimodal] Track encode cache entries by mm_hash and enable embedding sharing between requests](https://github.com/vllm-project/vllm/pull/22711) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-12 | 2025-08-25 07:41:17 UTC | 366 | 155 |
| [[Bugfix] SharedStorage Connector for V1 PD multimodal](https://github.com/vllm-project/vllm/pull/21611) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-07-25 | 2025-07-30 16:18:37 UTC | 244 | 12 |
| **Total for Chenguang Zheng** | | | | - | **5,648** | **233** |

### üë§ Samit (@SamitHuang) - ÊÄªË¥°ÁåÆ: 3
**‰ª£Á†ÅÂèòÊõ¥**: +418 Ë°åÊ∑ªÂä†, -2 Ë°åÂà†Èô§

**Pull Requests (0 open, 3 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [[RL] Add Pause and Resume Generation for Asynchronous RL Training](https://github.com/vllm-project/vllm/pull/28037) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-11-04 | 2025-11-20 11:01:03 UTC | 182 | 0 |
| [[Model] Switch to Fused RMSNorm in GLM-4.1V model](https://github.com/vllm-project/vllm/pull/24733) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-09-12 | 2025-09-12 16:12:23 UTC | 3 | 2 |
| [Add Qwen2.5VL Guide](https://github.com/vllm-project/recipes/pull/30) | [vllm-project/recipes](https://github.com/vllm-project/recipes) | `merged` | 2025-08-19 | 2025-08-22 10:56:12 UTC | 233 | 0 |
| **Total for Samit** | | | | - | **418** | **2** |

### üë§ Junhong Liu (@LJH-LBJ) - ÊÄªË¥°ÁåÆ: 2
**‰ª£Á†ÅÂèòÊõ¥**: +156 Ë°åÊ∑ªÂä†, -6 Ë°åÂà†Èô§

**Pull Requests (0 open, 2 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [Speed up mm processor kwargs per request by spliting dynamic and static kwargs](https://github.com/vllm-project/vllm/pull/26483) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-10-09 | 2025-11-06 23:51:28 UTC | 155 | 3 |
| [Remove Redundant Assignment in Qwen3_VisionPatchMerger](https://github.com/vllm-project/vllm/pull/25224) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-09-19 | 2025-09-19 18:15:13 UTC | 1 | 3 |
| **Total for Junhong Liu** | | | | - | **156** | **6** |

### üë§ knlnguyen1802 - ÊÄªË¥°ÁåÆ: 2
**‰ª£Á†ÅÂèòÊõ¥**: +755 Ë°åÊ∑ªÂä†, -111 Ë°åÂà†Èô§

**Pull Requests (2 open, 0 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [[RL] Support weight update with multi ipc handles + zmq](https://github.com/vllm-project/vllm/pull/28607) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `open` | 2025-11-13 | - | 319 | 90 |
| [[Bugfix] Missing cached item in the MultiModalReceiverCache](https://github.com/vllm-project/vllm/pull/28525) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `open` | 2025-11-12 | - | 436 | 21 |
| **Total for knlnguyen1802** | | | | - | **755** | **111** |

### üë§ Jinheng (@ahengljh) - ÊÄªË¥°ÁåÆ: 2
**‰ª£Á†ÅÂèòÊõ¥**: +198 Ë°åÊ∑ªÂä†, -8 Ë°åÂà†Èô§

**Pull Requests (0 open, 2 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [Add deprecation warning for lora_extra_vocab_size](https://github.com/vllm-project/vllm/pull/23635) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-26 | 2025-08-28 05:34:29 UTC | 8 | 2 |
| [feat(multimodal): Add customizable background color for RGBA to RGB conversion](https://github.com/vllm-project/vllm/pull/22052) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-01 | 2025-08-01 13:07:34 UTC | 190 | 6 |
| **Total for Jinheng** | | | | - | **198** | **8** |

### üë§ NATURE (@natureofnature) - ÊÄªË¥°ÁåÆ: 1
**‰ª£Á†ÅÂèòÊõ¥**: +1,242 Ë°åÊ∑ªÂä†, -3 Ë°åÂà†Èô§

**Pull Requests (1 open, 0 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [[Feature] DCCP supported](https://github.com/vllm-project/vllm/pull/23545) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `open` | 2025-08-25 | - | 1,242 | 3 |
| **Total for NATURE** | | | | - | **1,242** | **3** |

### üë§ Syed Muhammad Bin Asif (@syedmba) - ÊÄªË¥°ÁåÆ: 1
**‰ª£Á†ÅÂèòÊõ¥**: +40 Ë°åÊ∑ªÂä†, -16 Ë°åÂà†Èô§

**Pull Requests (0 open, 1 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [[Bugfix] Add proper comparison for package versions](https://github.com/vllm-project/vllm/pull/22314) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `merged` | 2025-08-06 | 2025-08-07 03:31:03 UTC | 40 | 16 |
| **Total for Syed Muhammad Bin Asif** | | | | - | **40** | **16** |

### üë§ chickeyton - ÊÄªË¥°ÁåÆ: 1
**‰ª£Á†ÅÂèòÊõ¥**: +375 Ë°åÊ∑ªÂä†, -60 Ë°åÂà†Èô§

**Pull Requests (1 open, 0 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [[Feat][Router] Add TTFT Routing](https://github.com/vllm-project/production-stack/pull/670) | [vllm-project/production-stack](https://github.com/vllm-project/production-stack) | `open` | 2025-09-01 | - | 375 | 60 |
| **Total for chickeyton** | | | | - | **375** | **60** |

### üë§ amy-why-3459 - ÊÄªË¥°ÁåÆ: 1
**‰ª£Á†ÅÂèòÊõ¥**: +73 Ë°åÊ∑ªÂä†, -11 Ë°åÂà†Èô§

**Pull Requests (1 open, 0 merged)**
| Title | Repository | State | Created | Merged | Additions | Deletions |
| ----- | ---------- | ----- | ------- | ------ | --------- | --------- |
| [[Core] Encoder separation for Encode-Prefill-Decode Disaggregation](https://github.com/vllm-project/vllm-ascend/pull/4176) | [vllm-project/vllm-ascend](https://github.com/vllm-project/vllm-ascend) | `open` | 2025-11-13 | - | 73 | 11 |
| **Total for amy-why-3459** | | | | - | **73** | **11** |

### üë§ R2-Y - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üë§ Gao Han (@Gaohan123) - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üë§ jiangkuaixue123 - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üë§ tangtiangu - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üë§ dengyunyang (@Bounty-hunter) - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üë§ Alicia (@congw729) - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üë§ zhuangzl (@godnight) - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üë§ herotai214 - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üë§ John Liu BUAA (@JohnLiu97Huawei) - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üë§ Zhou Taichang (@tzhouam) - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üë§ Zeng Chuang (@zengchuang-hw) - ÊÄªË¥°ÁåÆ: 0
**‰ª£Á†ÅÂèòÊõ¥**: +0 Ë°åÊ∑ªÂä†, -0 Ë°åÂà†Èô§

**Pull Requests (0 open, 0 merged)**
_No relevant pull requests found._

### üìä PR ÊÄªËßàÔºàÊåâÂàÜÁ±ªÊéíÂ∫èÔºâ
| Category | Title | Repository | User | State | Created | Merged | Additions | Deletions |
| -------- | ----- | ---------- | ---- | ----- | ------- | ------ | --------- | --------- |
| Feature | [feat(multimodal): Add customizable background color for RGBA to RGB conversion](https://github.com/vllm-project/vllm/pull/22052) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `ahengljh` | `merged` | 2025-08-01 | 2025-08-01 13:07:34 UTC | 190 | 6 |
| Feature | [[Core][Multimodal] Track encode cache entries by mm_hash and enable embedding sharing between requests](https://github.com/vllm-project/vllm/pull/22711) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `fake0fan` | `merged` | 2025-08-12 | 2025-08-25 07:41:17 UTC | 366 | 155 |
| Feature | [[Multimodal][Speculative Decoding]Eagle Eagle3 mm support, enablement on qwen2.5vl](https://github.com/vllm-project/vllm/pull/22872) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-08-14 | 2025-09-27 03:35:48 UTC | 210 | 45 |
| Feature | [[Model] Support dp on ViT on GLM-4.5V](https://github.com/vllm-project/vllm/pull/23168) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-08-19 | 2025-09-02 10:48:19 UTC | 145 | 59 |
| Feature | [[Model] Support DP for ViT on MiniCPM-V-4](https://github.com/vllm-project/vllm/pull/23327) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-08-21 | 2025-08-23 02:14:42 UTC | 105 | 30 |
| Feature | [[Feature][Responses API] Support MCP tool in background mode](https://github.com/vllm-project/vllm/pull/23494) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `wuhang2014` | `merged` | 2025-08-24 | 2025-08-27 01:06:58 UTC | 164 | 136 |
| Feature | [[Feature] DCCP supported](https://github.com/vllm-project/vllm/pull/23545) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `natureofnature` | `open` | 2025-08-25 | - | 1,242 | 3 |
| Feature | [Add deprecation warning for lora_extra_vocab_size](https://github.com/vllm-project/vllm/pull/23635) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `ahengljh` | `merged` | 2025-08-26 | 2025-08-28 05:34:29 UTC | 8 | 2 |
| Feature | [[Model] Support DP for ViT on Kimi-VL-A3B-Thinking-2506](https://github.com/vllm-project/vllm/pull/23817) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-08-28 | 2025-09-01 16:56:57 UTC | 157 | 62 |
| Feature | [[Feature][Responses API]Support MCP tools with streaming mode + background mode](https://github.com/vllm-project/vllm/pull/23927) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `wuhang2014` | `merged` | 2025-08-29 | 2025-09-04 04:05:10 UTC | 138 | 26 |
| Feature | [[Feat][Router] Add TTFT Routing](https://github.com/vllm-project/production-stack/pull/670) | [vllm-project/production-stack](https://github.com/vllm-project/production-stack) | `chickeyton` | `open` | 2025-09-01 | - | 375 | 60 |
| Feature | [[Spec Decoding]Support Spec Decoding Metrics in DP Mode](https://github.com/vllm-project/vllm/pull/24049) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `wuhang2014` | `merged` | 2025-09-01 | 2025-09-14 21:11:10 UTC | 54 | 38 |
| Feature | [[gpt-oss]Support lazy init mcp session](https://github.com/vllm-project/vllm/pull/24388) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `wuhang2014` | `open` | 2025-09-07 | - | 99 | 62 |
| Feature | [[Core] Encoder separation for Encode-Prefill-Decode Disaggregation](https://github.com/vllm-project/vllm/pull/25233) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `fake0fan` | `merged` | 2025-09-19 | 2025-11-12 02:58:34 UTC | 5,025 | 41 |
| Feature | [[RL] Add Pause and Resume Generation for Asynchronous RL Training](https://github.com/vllm-project/vllm/pull/28037) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `SamitHuang` | `merged` | 2025-11-04 | 2025-11-20 11:01:03 UTC | 182 | 0 |
| Feature | [[RL] Support weight update with multi ipc handles + zmq](https://github.com/vllm-project/vllm/pull/28607) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `knlnguyen1802` | `open` | 2025-11-13 | - | 319 | 90 |
| Feature | [[Core] Encoder separation for Encode-Prefill-Decode Disaggregation](https://github.com/vllm-project/vllm-ascend/pull/4176) | [vllm-project/vllm-ascend](https://github.com/vllm-project/vllm-ascend) | `amy-why-3459` | `open` | 2025-11-13 | - | 73 | 11 |
| Performance | [[EPLB] Optimize EPLB for Async Rearrange Experts ](https://github.com/vllm-project/vllm/pull/22179) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-08-04 | 2025-11-24 14:08:29 UTC | 778 | 77 |
| Performance | [[Feature][P/D]: Optimize NIXL Connector xfer Launch](https://github.com/vllm-project/vllm/pull/23887) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-08-29 | 2025-09-03 19:14:30 UTC | 18 | 13 |
| Performance | [[Multi-modality][performance] enable DP for ViT in Qwen-2.5-VL](https://github.com/vllm-project/vllm-ascend/pull/2709) | [vllm-project/vllm-ascend](https://github.com/vllm-project/vllm-ascend) | `hsliuustc0106` | `open` | 2025-09-02 | - | 47 | 13 |
| Performance | [[Performance][MM] Building the inverse permutation in O(n) time in Qwen2_5_VisionTransformer](https://github.com/vllm-project/vllm/pull/24443) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-09-08 | 2025-09-09 07:24:11 UTC | 11 | 1 |
| Performance | [[WIP][performance] DP for ViT in Intern S1 model](https://github.com/vllm-project/vllm/pull/24936) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `hsliuustc0106` | `open` | 2025-09-16 | - | 86 | 22 |
| Performance | [Speed up mm processor kwargs per request by spliting dynamic and static kwargs](https://github.com/vllm-project/vllm/pull/26483) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `LJH-LBJ` | `merged` | 2025-10-09 | 2025-11-06 23:51:28 UTC | 155 | 3 |
| Bugfix | [[BugFix] Fix shared storage connector load kv only load attention layer](https://github.com/vllm-project/vllm/pull/21428) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-07-23 | 2025-07-26 14:07:41 UTC | 10 | 2 |
| Bugfix | [[Bugfix] Fix example disagg_example_p2p_nccl_xpyd.sh zombie process](https://github.com/vllm-project/vllm/pull/21437) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-07-23 | 2025-07-24 03:42:11 UTC | 1 | 0 |
| Bugfix | [[Bugfix] [issue-21565] Fix the incompatibility issue with stream and named function calling when Thinking is disabled](https://github.com/vllm-project/vllm/pull/21573) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `hsliuustc0106` | `merged` | 2025-07-25 | 2025-07-28 05:43:50 UTC | 23 | 7 |
| Bugfix | [[Bugfix] SharedStorage Connector for V1 PD multimodal](https://github.com/vllm-project/vllm/pull/21611) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `fake0fan` | `merged` | 2025-07-25 | 2025-07-30 16:18:37 UTC | 244 | 12 |
| Bugfix | [[Bugfix]check health for engine core process exiting unexpectedly](https://github.com/vllm-project/vllm/pull/21728) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `wuhang2014` | `merged` | 2025-07-28 | 2025-07-28 13:17:31 UTC | 84 | 2 |
| Bugfix | [[Docs] Fix the example code of streaming chat completions in reasoning](https://github.com/vllm-project/vllm/pull/21825) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `hsliuustc0106` | `merged` | 2025-07-29 | 2025-07-30 12:11:58 UTC | 12 | 14 |
| Bugfix | [[Bugfix] Add log prefix in non-dp mode engine core](https://github.com/vllm-project/vllm/pull/21889) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `wuhang2014` | `merged` | 2025-07-30 | 2025-08-01 09:04:16 UTC | 75 | 81 |
| Bugfix | [[Bugfix] Fix hermes tool parser handling of non-string argument types](https://github.com/vllm-project/vllm/pull/22002) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-07-31 | 2025-09-22 03:35:39 UTC | 166 | 7 |
| Bugfix | [[Doc] Fix a syntax error of example code in structured_outputs.md](https://github.com/vllm-project/vllm/pull/22045) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `hsliuustc0106` | `merged` | 2025-08-01 | 2025-08-01 07:01:22 UTC | 1 | 1 |
| Bugfix | [[Bugfix] EPLB load statistics problem](https://github.com/vllm-project/vllm/pull/22167) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-08-04 | 2025-08-07 04:07:54 UTC | 26 | 41 |
| Bugfix | [[Bugfix] Add proper comparison for package versions](https://github.com/vllm-project/vllm/pull/22314) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `syedmba` | `merged` | 2025-08-06 | 2025-08-07 03:31:03 UTC | 40 | 16 |
| Bugfix | [[Bugfix]Fix EEP scale-up functionality](https://github.com/vllm-project/vllm/pull/22953) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `wuhang2014` | `open` | 2025-08-15 | - | 133 | 7 |
| Bugfix | [[Bugfix]Enable zmq router handover to handle scaling-up after scaling-down in EEP](https://github.com/vllm-project/vllm/pull/23247) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `wuhang2014` | `open` | 2025-08-20 | - | 3 | 0 |
| Bugfix | [[bugfix] Missing cached item in beam search](https://github.com/vllm-project/vllm/pull/27874) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `fake0fan` | `merged` | 2025-10-31 | 2025-10-31 17:34:28 UTC | 10 | 18 |
| Bugfix | [[CI/Build] Fix crash due to removed VLLM_USE_V1 attribute in EPD](https://github.com/vllm-project/vllm/pull/28521) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `fake0fan` | `merged` | 2025-11-12 | 2025-11-12 07:09:33 UTC | 3 | 7 |
| Bugfix | [[Bugfix] Missing cached item in the MultiModalReceiverCache](https://github.com/vllm-project/vllm/pull/28525) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `knlnguyen1802` | `open` | 2025-11-12 | - | 436 | 21 |
| Docs | [[Docs] add offline serving multi-modal video input expamle Qwen2.5-VL](https://github.com/vllm-project/vllm/pull/21530) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-07-24 | 2025-07-26 01:37:32 UTC | 64 | 0 |
| Docs | [[Doc] Added unmentioned required option "method" in the usage of EAGLE-3 based models](https://github.com/vllm-project/vllm/pull/21737) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `hsliuustc0106` | `merged` | 2025-07-28 | 2025-08-12 07:14:51 UTC | 4 | 0 |
| Docs | [[Doc] Added warning of speculating with draft model](https://github.com/vllm-project/vllm/pull/22047) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-08-01 | 2025-08-01 09:11:56 UTC | 4 | 0 |
| Docs | [[Docs] Update features/disagg_prefill, add v1 examples and development](https://github.com/vllm-project/vllm/pull/22165) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-08-04 | 2025-08-07 07:59:23 UTC | 25 | 0 |
| Docs | [[Doc][GPT-OSS]Background mode for built-in mcp tools](https://github.com/vllm-project/recipes/pull/45) | [vllm-project/recipes](https://github.com/vllm-project/recipes) | `wuhang2014` | `merged` | 2025-08-30 | 2025-09-02 23:38:55 UTC | 1 | 1 |
| Docs | [[Doc][gpt-oss]Responses API supports streaming with built-in tools with MCP](https://github.com/vllm-project/recipes/pull/48) | [vllm-project/recipes](https://github.com/vllm-project/recipes) | `wuhang2014` | `merged` | 2025-09-04 | 2025-09-04 05:18:20 UTC | 1 | 1 |
| Docs | [[Docs] GSM8K Accuracy Evaluation doc update](https://github.com/vllm-project/vllm/pull/25360) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-09-22 | 2025-09-22 02:49:13 UTC | 1 | 1 |
| Other | [[Model] Switch to Fused RMSNorm in GLM-4.1V model](https://github.com/vllm-project/vllm/pull/24733) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `SamitHuang` | `merged` | 2025-09-12 | 2025-09-12 16:12:23 UTC | 3 | 2 |
| Other | [Remove Redundant Assignment in Qwen3_VisionPatchMerger](https://github.com/vllm-project/vllm/pull/25224) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `LJH-LBJ` | `merged` | 2025-09-19 | 2025-09-19 18:15:13 UTC | 1 | 3 |
| Other | [[Misc] remove useless v1 env](https://github.com/vllm-project/vllm/pull/29164) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `merged` | 2025-11-21 | 2025-11-21 09:41:20 UTC | 0 | 2 |
| Other | [vllm-omni post init and roadmap updates](https://github.com/vllm-project/vllm-project.github.io/pull/123) | [vllm-project/vllm-project.github.io](https://github.com/vllm-project/vllm-project.github.io) | `hsliuustc0106` | `open` | 2025-11-28 | - | 109 | 0 |
| Test | [Add Qwen2.5VL Guide](https://github.com/vllm-project/recipes/pull/30) | [vllm-project/recipes](https://github.com/vllm-project/recipes) | `SamitHuang` | `merged` | 2025-08-19 | 2025-08-22 10:56:12 UTC | 233 | 0 |
| Test | [[Seed] Add Seed-OSS Guide](https://github.com/vllm-project/recipes/pull/41) | [vllm-project/recipes](https://github.com/vllm-project/recipes) | `david6666666` | `merged` | 2025-08-26 | 2025-08-28 08:14:21 UTC | 199 | 1 |
| Test | [[Benchmarks]Accelerate random dataset generation](https://github.com/vllm-project/vllm/pull/24225) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `wuhang2014` | `open` | 2025-09-04 | - | 86 | 11 |
| Test | [[CI][gpt-oss] Enable python tool tests in CI](https://github.com/vllm-project/vllm/pull/24315) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `wuhang2014` | `merged` | 2025-09-05 | 2025-10-06 04:20:07 UTC | 24 | 26 |
| Test | [[CI] Add Async Eplb nightly CI tests](https://github.com/vllm-project/vllm/pull/29385) | [vllm-project/vllm](https://github.com/vllm-project/vllm) | `david6666666` | `open` | 2025-11-25 | - | 167 | 4 |

